{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d452bb8e",
   "metadata": {},
   "source": [
    "### 1. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1539d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\biagu\\Documents\\GitHub\\social_graphs_project\\data\\processed\n",
      "Nodes loaded: 2410\n",
      "Edges loaded: 4805\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community.community_louvain as community_louvain \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION & SETUP\n",
    "# ==========================================\n",
    "# Exact path from your provided code\n",
    "PROCESSED_DIR = Path(\"C:/Users/biagu/Documents/GitHub/social_graphs_project/data/processed\")\n",
    "\n",
    "NODES_PATH = PROCESSED_DIR / \"nodes_enriched.csv\"\n",
    "EDGES_PATH = PROCESSED_DIR / \"edges_enriched.csv\"\n",
    "OUTPUT_PATH = PROCESSED_DIR / \"nodes_analyzed.csv\"\n",
    "\n",
    "print(f\"Loading data from: {PROCESSED_DIR}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. BUILD GRAPH\n",
    "# ==========================================\n",
    "nodes_df = pd.read_csv(NODES_PATH)\n",
    "edges_df = pd.read_csv(EDGES_PATH)\n",
    "\n",
    "print(f\"Nodes loaded: {len(nodes_df)}\")\n",
    "print(f\"Edges loaded: {len(edges_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38c25f",
   "metadata": {},
   "source": [
    "## 2. Build graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e47bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph constructed: 2410 nodes, 4669 edges.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add Nodes\n",
    "for _, row in nodes_df.iterrows():\n",
    "    # We treat 'node_id' as the unique identifier\n",
    "    G.add_node(row['node_id'], \n",
    "               name=row['name'], \n",
    "               type=row['node_type'], \n",
    "               description=str(row['description']))\n",
    "\n",
    "# Add Edges\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row['source'], row['target'], \n",
    "               relation=row['relationship'], \n",
    "               type=row['edge_type'])\n",
    "\n",
    "print(f\"Graph constructed: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545113fa",
   "metadata": {},
   "source": [
    "### 3. Community detection (The factions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f297b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Detecting Communities (Louvain) ---\n",
      "Total Communities Detected: 542\n",
      "\n",
      "Top 10 Largest Communities:\n",
      "community\n",
      "9      308\n",
      "6      202\n",
      "41     201\n",
      "97     148\n",
      "135    102\n",
      "16      99\n",
      "42      92\n",
      "1       80\n",
      "114     74\n",
      "129     74\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Community Membership Preview ---\n",
      "\n",
      "Community 9 (Size: 308):\n",
      "  Sample Members: Bloody Finger, Grave Glovewort [1], Grave Glovewort [2], Ghost Glovewort [1], Fireproof Dried Liver, Fire Grease, Throwing Dagger, Remembrance Of The Blasphemous...\n",
      "\n",
      "Community 6 (Size: 202):\n",
      "  Sample Members: Memory Of Grace, Smithing Stone [2], Ancient Dragon Smithing Stone, Somber Ancient Dragon Smithing Stone, Rowa Raisin, Pauper's Rune, Pickled Turtle Neck, Gold-pickled Fowl Foot...\n",
      "\n",
      "Community 41 (Size: 201):\n",
      "  Sample Members: Armorer's Cookbook [2], Armorer's Cookbook [3], Armorer's Cookbook [4], Armorer's Cookbook [1], Armorer's Cookbook [6], Armorer's Cookbook [7], Hero's Rune [1], Celebrant's Cleaver...\n",
      "\n",
      "Community 97 (Size: 148):\n",
      "  Sample Members: Baldachin's Blessing, Remembrance Of The Grafted, Remembrance Of The Naturalborn, Remembrance Of The Omen King, Remembrance Of The Dragonlord, Dragonlord Placidusax, Placidusax's Ruin, Crucible Axe Set...\n",
      "\n",
      "Community 135 (Size: 102):\n",
      "  Sample Members: Great Grave Glovewort, Remembrance Of The Fire Giant, Elden Remembrance, Remembrance Of The Rot Goddess, Shabriri Grape, Rold Medallion, Haligtree Secret Medallion (left), Haligtree Secret Medallion (right)...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. COMMUNITY DETECTION (The Factions)\n",
    "# ==========================================\n",
    "print(\"\\n--- Detecting Communities (Louvain) ---\")\n",
    "# Compute partition\n",
    "partition = community_louvain.best_partition(G)\n",
    "\n",
    "# Add 'community' column to the DataFrame\n",
    "nodes_df['community'] = nodes_df['node_id'].map(partition)\n",
    "\n",
    "# Analyze Community Sizes\n",
    "comm_counts = nodes_df['community'].value_counts()\n",
    "print(f\"Total Communities Detected: {len(comm_counts)}\")\n",
    "print(\"\\nTop 10 Largest Communities:\")\n",
    "print(comm_counts.head(10))\n",
    "\n",
    "# Print sample members of top communities to verify they make sense\n",
    "print(\"\\n--- Community Membership Preview ---\")\n",
    "for comm_id in comm_counts.head(5).index:\n",
    "    members = nodes_df[nodes_df['community'] == comm_id]['name'].tolist()\n",
    "    # Handle cases where names might be missing/NaN\n",
    "    clean_members = [str(m) for m in members if pd.notna(m)]\n",
    "    print(f\"\\nCommunity {comm_id} (Size: {len(members)}):\")\n",
    "    print(f\"  Sample Members: {', '.join(clean_members[:8])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a85a6",
   "metadata": {},
   "source": [
    "### 4. Centrality Analysis (The \"True\" Lore Bridges)\n",
    "Here we calculate Betweenness Centrality. Crucially, we filter out generic \"Wiki Header\" nodes (like \"Items\" or \"Weapons\") that distort the graph, ensuring we find the true narrative bridges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72626b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Centrality (Filtered) ---\n",
      "Temporarily removed 8 generic header nodes for accurate lore analysis.\n",
      "\n",
      "Top 15 Most Central Characters/Items (Lore Accurate):\n",
      "                       name node_type  centrality\n",
      "2390               Strength    weapon    0.134970\n",
      "1900                  Armor      boss    0.129357\n",
      "2295              Dexterity    weapon    0.076896\n",
      "2133  Shadow of the Erdtree      boss    0.075557\n",
      "2162      The Lands Between      boss    0.058631\n",
      "2153                  Stats      boss    0.036609\n",
      "2121                  Runes      boss    0.030936\n",
      "2154         Status Effects      boss    0.028386\n",
      "2035               Limgrave      boss    0.023754\n",
      "2085                 Poison      boss    0.021008\n",
      "2129            Scarlet Rot      boss    0.018518\n",
      "2238            Two Fingers       npc    0.017792\n",
      "2037   Liurnia of the Lakes      boss    0.017696\n",
      "2335           Intelligence    weapon    0.016309\n",
      "1928                 Caelid      boss    0.014988\n",
      "\n",
      "✅ Analysis Complete. Saved results to: C:\\Users\\biagu\\Documents\\GitHub\\social_graphs_project\\data\\processed\\nodes_analyzed.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. CENTRALITY ANALYSIS (The \"True\" Lore Bridges)\n",
    "# ==========================================\n",
    "print(\"\\n--- Calculating Centrality (Filtered) ---\")\n",
    "\n",
    "# 1. Define Generic Wiki Headers to Filter Out\n",
    "# These distort centrality because everything links to \"Items\" or \"Weapons\"\n",
    "generic_headers = [\n",
    "    \"Items\", \"Weapons\", \"Armors\", \"Incantations\", \"Sorceries\", \n",
    "    \"Talismans\", \"Ash of War\", \"Spirit Ashes\", \"Shields\", \n",
    "    \"Consumables\", \"Key Items\", \"Bosses\", \"NPCs\", \"Locations\",\n",
    "    \"Creatures\", \"Enemies\", \"Materials\"\n",
    "]\n",
    "\n",
    "# 2. Create a temporary view of the graph without these nodes\n",
    "G_lore = G.copy()\n",
    "nodes_to_remove = [n for n, data in G_lore.nodes(data=True) if data.get('name') in generic_headers]\n",
    "G_lore.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "print(f\"Temporarily removed {len(nodes_to_remove)} generic header nodes for accurate lore analysis.\")\n",
    "\n",
    "# 3. Calculate Betweenness Centrality\n",
    "betweenness = nx.betweenness_centrality(G_lore)\n",
    "\n",
    "# 4. Map back to DataFrame (fill NaN with 0 for nodes we removed)\n",
    "nodes_df['centrality'] = nodes_df['node_id'].map(betweenness).fillna(0)\n",
    "\n",
    "# 5. Show Top Characters\n",
    "print(\"\\nTop 15 Most Central Characters/Items (Lore Accurate):\")\n",
    "print(nodes_df[['name', 'node_type', 'centrality']]\n",
    "      .sort_values('centrality', ascending=False)\n",
    "      .head(15))\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXPORT RESULTS\n",
    "# ==========================================\n",
    "# Save the dataframe with 'community' and 'centrality' added\n",
    "nodes_df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"\\n✅ Analysis Complete. Saved results to: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
